# Create an RDD from the external text file. Find the word count in the text file using various transformation and action functions in PySpark.

from google.colab import files
uploaded = files.upload()
!pip install pyspark
from pyspark import SparkContext 
from pyspark.sql.session import SparkSession
spark=SparkSession.builder.appName("wordcount").getOrCreate()
# change the path here 
text_file=spark.read.text("/content/test.txt")
words=text_file.rdd.flatMap(lambda line:line.value.split(" "))
word_count=words.count()
print("number of words in text fiel:",word_count)
